{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a23b990e"
      },
      "source": [
        "# Imports"
      ],
      "id": "a23b990e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1wAJl5bu1Yr"
      },
      "outputs": [],
      "source": [
        "!pip install -q git+https://github.com/tensorflow/docs"
      ],
      "id": "Q1wAJl5bu1Yr"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aj5gvxXEwERW"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow-addons"
      ],
      "id": "Aj5gvxXEwERW"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dc6f2737",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.transform import resize\n",
        "from tensorflow.keras.utils import plot_model\n",
        "import pathlib\n",
        "import imageio\n",
        "import glob\n",
        "import PIL\n",
        "import nibabel as nib\n",
        "import os\n",
        "from tkinter import Tcl\n",
        "import cv2\n",
        "import tensorflow_docs.vis.embed as embed\n",
        "import tensorflow_addons.layers as tfal\n",
        "from keras.initializers import RandomNormal\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input,Conv2D,Conv2DTranspose,LeakyReLU,Activation,Concatenate,Add\n",
        "from scipy import ndimage\n",
        "import shutil\n",
        "import json\n",
        "import tensorflow.keras.layers as L"
      ],
      "id": "dc6f2737"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YULfoy4A0Vz_",
        "outputId": "6f7014bb-2d3c-4604-8aca-8b6e6d281a3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "YULfoy4A0Vz_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8odvQepuR9E"
      },
      "outputs": [],
      "source": [
        "class InstanceNormalization(tf.keras.layers.Layer):\n",
        "    def __init__(self, epsilon=1e-5):\n",
        "        super(InstanceNormalization, self).__init__()\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.scale = self.add_weight(\n",
        "            name='scale',\n",
        "            shape=input_shape[-1:],\n",
        "            initializer=tf.random_normal_initializer(1., 0.02),\n",
        "            trainable=True)\n",
        "        self.offset = self.add_weight(\n",
        "            name='offset',\n",
        "            shape=input_shape[-1:],\n",
        "            initializer='zeros',\n",
        "            trainable=True)\n",
        "\n",
        "    def call(self, x):\n",
        "        mean, variance = tf.nn.moments(x, axes=[1, 2], keepdims=True)\n",
        "        inv = tf.math.rsqrt(variance + self.epsilon)\n",
        "        normalized = (x - mean) * inv\n",
        "        return self.scale * normalized + self.offset\n",
        "\n",
        "\n",
        "class SqueezeAttention():\n",
        "    def __init__(self):\n",
        "        self.model = self.squeeze_attention_unet()\n",
        "\n",
        "    def conv_block(self, x, num_filters):\n",
        "        x = L.Conv2D(num_filters, 3, padding=\"same\")(x)\n",
        "        x = tfal.InstanceNormalization(axis=-1)(x)\n",
        "        x = L.Activation(\"relu\")(x)\n",
        "\n",
        "        x = L.Conv2D(num_filters, 3, padding=\"same\")(x)\n",
        "        x = tfal.InstanceNormalization(axis=-1)(x)\n",
        "        x = L.Activation(\"relu\")(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def se_block(self, x, num_filters, ratio=8):\n",
        "        se_shape = (1, 1, num_filters)\n",
        "        se = L.GlobalAveragePooling2D()(x)\n",
        "        se = L.Reshape(se_shape)(se)\n",
        "        se = L.Dense(num_filters // ratio, activation=\"relu\", use_bias=False)(se)\n",
        "        se = L.Dense(num_filters, activation=\"sigmoid\", use_bias=False)(se)\n",
        "        se = L.Reshape(se_shape)(se)\n",
        "        x = L.Multiply()([x, se])\n",
        "        return x\n",
        "\n",
        "    def encoder_block(self, x, num_filters):\n",
        "        x = self.conv_block(x, num_filters)\n",
        "        x = self.se_block(x, num_filters)\n",
        "        p = L.MaxPool2D((2, 2))(x)\n",
        "        return x, p\n",
        "\n",
        "    def decoder_block(self, x, s, num_filters):\n",
        "        x = L.UpSampling2D(interpolation=\"bilinear\")(x)\n",
        "        x = L.Concatenate()([x, s])\n",
        "        x = self.conv_block(x, num_filters)\n",
        "        x = self.se_block(x, num_filters)\n",
        "        return x\n",
        "\n",
        "    def squeeze_attention_unet(self, input_shape=(256, 256, 3)):\n",
        "        \"\"\" Inputs \"\"\"\n",
        "        inputs = L.Input(input_shape)\n",
        "\n",
        "        \"\"\" Encoder \"\"\"\n",
        "        s1, p1 = self.encoder_block(inputs, 64)\n",
        "        s2, p2 = self.encoder_block(p1, 128)\n",
        "        s3, p3 = self.encoder_block(p2, 256)\n",
        "        s4, p4 = self.encoder_block(p3, 256)\n",
        "\n",
        "        b1 = self.conv_block(p4, 512)\n",
        "        b1 = self.se_block(b1, 512)\n",
        "\n",
        "        \"\"\" Decoder \"\"\"\n",
        "        d = self.decoder_block(b1, s4, 256)\n",
        "        d1 = self.decoder_block(d, s3, 256)\n",
        "        d2 = self.decoder_block(d1, s2, 128)\n",
        "        d3 = self.decoder_block(d2, s1, 64)\n",
        "\n",
        "        \"\"\" Outputs \"\"\"\n",
        "        outputs = L.Conv2D(3, (1, 1), activation='tanh')(d3)\n",
        "\n",
        "        \"\"\" Model \"\"\"\n",
        "\n",
        "        model = Model(inputs, outputs, name=\"Squeeze-Attention-UNET\")\n",
        "        return model\n",
        "\n",
        "class ResNet():\n",
        "    def __init__(self):\n",
        "        self.model = self.resnet_generator()\n",
        "\n",
        "    def resnet_block(self, n_filters, input_layer):\n",
        "        # weight initialization\n",
        "        init = RandomNormal(stddev=0.02)\n",
        "        # first layer convolutional layer\n",
        "        g = Conv2D(n_filters, (3, 3), padding='same', kernel_initializer=init)(input_layer)\n",
        "        g = tfal.InstanceNormalization(axis=-1)(g)\n",
        "        g = Activation('relu')(g)\n",
        "        # second convolutional layer\n",
        "        g = Conv2D(n_filters, (3, 3), padding='same', kernel_initializer=init)(g)\n",
        "        g = tfal.InstanceNormalization(axis=-1)(g)\n",
        "        # concatenate merge channel-wise with input layer\n",
        "        g = Concatenate()([g, input_layer])\n",
        "        return g\n",
        "\n",
        "    def resnet_generator(self, image_shape=(256, 256, 3), n_resnet=7):\n",
        "        # weight initialization\n",
        "        init = RandomNormal(stddev=0.02)\n",
        "        in_image = Input(shape=image_shape)\n",
        "        g = Conv2D(64, (7, 7), padding='same', kernel_initializer=init)(in_image)\n",
        "        g = tfal.InstanceNormalization(axis=-1)(g)\n",
        "        g = Activation('relu')(g)\n",
        "        g = Conv2D(128, (3, 3), strides=(2, 2), padding='same', kernel_initializer=init)(g)\n",
        "        g = tfal.InstanceNormalization(axis=-1)(g)\n",
        "        g = Activation('relu')(g)\n",
        "\n",
        "        g = Conv2D(256, (3, 3), strides=(2, 2), padding='same', kernel_initializer=init)(g)\n",
        "        g = tfal.InstanceNormalization(axis=-1)(g)\n",
        "        g = Activation('relu')(g)\n",
        "\n",
        "        for _ in range(n_resnet):\n",
        "            g = self.resnet_block(256, g)\n",
        "\n",
        "        g = Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same', kernel_initializer=init)(g)\n",
        "        g = tfal.InstanceNormalization(axis=-1)(g)\n",
        "        g = Activation('relu')(g)\n",
        "\n",
        "        g = Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same', kernel_initializer=init)(g)\n",
        "        g = tfal.InstanceNormalization(axis=-1)(g)\n",
        "        g = Activation('relu')(g)\n",
        "\n",
        "        g = Conv2D(3, (7, 7), padding='same', kernel_initializer=init)(g)\n",
        "        g = tfal.InstanceNormalization(axis=-1)(g)\n",
        "        out_image = Activation('tanh')(g)\n",
        "        # define model\n",
        "        model = Model(in_image, out_image)\n",
        "        return model\n",
        "\n",
        "\n",
        "class unet_model():\n",
        "    def __init__(self):\n",
        "        self.model = self.unet_generator()\n",
        "\n",
        "    def downsample(self, filters, size, apply_norm=True):\n",
        "        initializer = tf.random_normal_initializer(0., 0.02)\n",
        "        result = tf.keras.Sequential()\n",
        "        result.add(tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n",
        "                                          kernel_initializer=initializer, use_bias=False))\n",
        "        if apply_norm:\n",
        "            result.add(InstanceNormalization())\n",
        "        result.add(tf.keras.layers.LeakyReLU())\n",
        "        return result\n",
        "\n",
        "    def upsample(self, filters, size, apply_dropout=False):\n",
        "        initializer = tf.random_normal_initializer(0., 0.02)\n",
        "        result = tf.keras.Sequential()\n",
        "        result.add(tf.keras.layers.Conv2DTranspose(filters, size, strides=2, padding='same',\n",
        "                                                   kernel_initializer=initializer, use_bias=False))\n",
        "        result.add(InstanceNormalization())\n",
        "        if apply_dropout:\n",
        "            result.add(tf.keras.layers.Dropout(0.5))\n",
        "        result.add(tf.keras.layers.ReLU())\n",
        "        return result\n",
        "\n",
        "    def unet_generator(self):\n",
        "        down_stack = [\n",
        "            self.downsample(64, 4, False),\n",
        "            self.downsample(128, 4),\n",
        "            self.downsample(128, 4),\n",
        "            self.downsample(128, 4),\n",
        "            self.downsample(128, 4)\n",
        "        ]\n",
        "        up_stack = [\n",
        "            self.upsample(128, 4, True),\n",
        "            self.upsample(128, 4, True),\n",
        "            self.upsample(128, 4),\n",
        "            self.upsample(64, 4)\n",
        "        ]\n",
        "\n",
        "        initializer = tf.random_normal_initializer(0., 0.02)\n",
        "        last = tf.keras.layers.Conv2DTranspose(3, 4, strides=2, padding='same', kernel_initializer=initializer,\n",
        "                                               activation='tanh')\n",
        "        concat = tf.keras.layers.Concatenate()\n",
        "        inputs = tf.keras.layers.Input(shape=[256, 256, 3])\n",
        "        x = inputs\n",
        "        skips = []\n",
        "        for down in down_stack:\n",
        "            x = down(x)\n",
        "            skips.append(x)\n",
        "        skips = reversed(skips[:-1])\n",
        "        for up, skip in zip(up_stack, skips):\n",
        "            x = up(x)\n",
        "            x = concat([x, skip])\n",
        "        x = last(x)\n",
        "        return tf.keras.Model(inputs=inputs, outputs=x)\n",
        "\n",
        "\n",
        "class Discriminator(unet_model):\n",
        "    def __init__(self):\n",
        "        self.model = self.discriminator()\n",
        "\n",
        "    def discriminator(self):\n",
        "        initializer = tf.random_normal_initializer(0., 0.02)\n",
        "        inp = tf.keras.layers.Input(shape=[256, 256, 3], name='input_image')\n",
        "        x = inp\n",
        "        down1 = self.downsample(64, 4, False)(x)  # (bs, 16, 16, 64)\n",
        "        down2 = self.downsample(128, 4)(down1)\n",
        "        down3 = self.downsample(256, 4)(down2)\n",
        "        zero_pad1 = tf.keras.layers.ZeroPadding2D()(down3)  # (bs, 34, 34, 256)\n",
        "        conv = tf.keras.layers.Conv2D(512, 4, strides=1, kernel_initializer=initializer,\n",
        "                                      use_bias=False)(zero_pad1)  # (bs, 31, 31, 512)\n",
        "        norm1 = InstanceNormalization()(conv)\n",
        "        leaky_relu = tf.keras.layers.LeakyReLU()(norm1)\n",
        "        zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu)  # (bs, 33, 33, 512)\n",
        "        last = tf.keras.layers.Conv2D(1, 4, strides=1, kernel_initializer=initializer)(zero_pad2)  # (bs, 30, 30, 1)\n",
        "        return tf.keras.Model(inputs=inp, outputs=last)\n",
        "\n",
        "class old_squeeze():\n",
        "    def __init__(self):\n",
        "        self.model = self.squeeze_attention_unet()\n",
        "\n",
        "    def conv_block(self, x, num_filters):\n",
        "        x = L.Conv2D(num_filters, 3, padding=\"same\")(x)\n",
        "        x = tfal.InstanceNormalization(axis=-1)(x)\n",
        "        x = L.Activation(\"relu\")(x)\n",
        "\n",
        "        x = L.Conv2D(num_filters, 3, padding=\"same\")(x)\n",
        "        x = tfal.InstanceNormalization(axis=-1)(x)\n",
        "        x = L.Activation(\"relu\")(x)\n",
        "        return x\n",
        "\n",
        "    def se_block(self, x, num_filters, ratio=8):\n",
        "        se_shape = (1, 1, num_filters)\n",
        "        se = L.GlobalAveragePooling2D()(x)\n",
        "        se = L.Reshape(se_shape)(se)\n",
        "        se = L.Dense(num_filters // ratio, activation=\"relu\", use_bias=False)(se)\n",
        "        se = L.Dense(num_filters, activation=\"sigmoid\", use_bias=False)(se)\n",
        "        se = L.Reshape(se_shape)(se)\n",
        "        x = L.Multiply()([x, se])\n",
        "        return x\n",
        "\n",
        "    def encoder_block(self, x, num_filters):\n",
        "        x = self.conv_block(x, num_filters)\n",
        "        x = self.se_block(x, num_filters)\n",
        "        p = L.MaxPool2D((2, 2))(x)\n",
        "        return x, p\n",
        "\n",
        "    def decoder_block(self, x, s, num_filters):\n",
        "        x = L.UpSampling2D(interpolation=\"bilinear\")(x)\n",
        "        x = L.Concatenate()([x, s])\n",
        "        x = self.conv_block(x, num_filters)\n",
        "        x = self.se_block(x, num_filters)\n",
        "        return x\n",
        "\n",
        "    def squeeze_attention_unet(self, input_shape=(256, 256, 3)):\n",
        "        \"\"\" Inputs \"\"\"\n",
        "        inputs = L.Input(input_shape)\n",
        "\n",
        "        \"\"\" Encoder \"\"\"\n",
        "        s1, p1 = self.encoder_block(inputs, 64)\n",
        "        s2, p2 = self.encoder_block(p1, 128)\n",
        "        s3, p3 = self.encoder_block(p2, 256)\n",
        "\n",
        "        b1 = self.conv_block(p3, 512)\n",
        "        b1 = self.se_block(b1, 512)\n",
        "\n",
        "        \"\"\" Decoder \"\"\"\n",
        "        d1 = self.decoder_block(b1, s3, 256)\n",
        "        d2 = self.decoder_block(d1, s2, 128)\n",
        "        d3 = self.decoder_block(d2, s1, 64)\n",
        "\n",
        "        \"\"\" Outputs \"\"\"\n",
        "        outputs = L.Conv2D(3, (1, 1), activation='tanh')(d3)\n",
        "\n",
        "        \"\"\" Model \"\"\"\n",
        "        model = Model(inputs, outputs, name=\"Squeeze-Attention-UNET\")\n",
        "        return model"
      ],
      "id": "N8odvQepuR9E"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zODj5gQguc5I"
      },
      "outputs": [],
      "source": [
        "def preprocess_image_train(image):\n",
        "    image = (image/127.5)-1\n",
        "    return image\n",
        "\n",
        "# TO DO: Generalize Path, add it to arguments\n",
        "def generate_images_GIF(img_input, model, img_true, mode, order):\n",
        "    prediction = model(img_input)\n",
        "    pred_vol = prediction[0, :, :, 0].numpy().copy()\n",
        "    error = tf.image.ssim(img_true, prediction, max_val=2)\n",
        "    img_input = np.rot90(img_input[0, :, :, 0], 3)\n",
        "    img_true = np.rot90(img_true[0, :, :, 0], 3)\n",
        "    prediction = np.rot90(prediction[0, :, :, 0], 3)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    if mode == 1:\n",
        "        display_list = [img_input, prediction, img_true]\n",
        "        title = [f'{seq_1} True', f'{seq_2} predicted', f'{seq_2} True']\n",
        "\n",
        "    else:\n",
        "        display_list = [img_input, prediction, img_true]\n",
        "        title = [f'{seq_2} True', f'{seq_1} predicted', f'{seq_1} True']\n",
        "\n",
        "    plots_path_T1_FLAIR = r'E:\\Graduation Project\\GIFs and Models\\Brats {}\\Predicted\\{}-{}-GIF'.format(brats_num, seq_1,\n",
        "                                                                                                       seq_2)\n",
        "    plots_path_FLAIR_T1 = r'E:\\Graduation Project\\GIFs and Models\\Brats {}\\Predicted\\{}-{}-GIF'.format(brats_num, seq_2,\n",
        "                                                                                                       seq_1)\n",
        "    if not os.path.exists(plots_path_T1_FLAIR):\n",
        "        os.makedirs(plots_path_T1_FLAIR)\n",
        "    if not os.path.exists(plots_path_FLAIR_T1):\n",
        "        os.makedirs(plots_path_FLAIR_T1)\n",
        "\n",
        "    for i in range(3):\n",
        "        plt.subplot(1, 3, i + 1)\n",
        "        plt.title(title[i])\n",
        "        plt.imshow(display_list[i] * 0.5 + 0.5, cmap='gray')\n",
        "        plt.axis('off')\n",
        "        if mode == 1:\n",
        "            plt.savefig(\n",
        "                r'E:\\Graduation Project\\GIFs and Models\\Brats {}\\Predicted\\{}-{}-GIF\\{}.png'.format(brats_num, seq_1,\n",
        "                                                                                                    seq_2, order))\n",
        "        if mode == 2:\n",
        "            plt.savefig(\n",
        "                r'E:\\Graduation Project\\GIFs and Models\\Brats {}\\Predicted\\{}-{}-GIF\\{}.png'.format(brats_num, seq_2,\n",
        "                                                                                                    seq_1, order))\n",
        "    plt.show()\n",
        "    return error, pred_vol\n",
        "\n",
        "\n",
        "#TO DO: Generalize Path, add it to arguments\n",
        "def predict_image(img_input, model):\n",
        "    prediction = model(img_input)\n",
        "    pred_vol = prediction[0, :, :, 0].numpy().copy()\n",
        "    return pred_vol\n",
        "\n",
        "#TO DO: Generalize Path, add it to arguments\n",
        "def predict_image_and_calc_loss(img_input, model, img_true):\n",
        "    prediction = model(img_input)\n",
        "    pred_vol = prediction[0, :, :, 0].numpy().copy()\n",
        "    # error = tf.image.ssim(img_true, prediction, max_val=2)\n",
        "    return 0, pred_vol\n",
        "\n",
        "def black_seq_generator(test_path, brats_num, T1_FLAG=True, T2_FLAG=True, FLAIR_FLAG=True):\n",
        "    test_data_list = sorted(glob.glob(test_path + '/*'))\n",
        "    original_vol_path = sorted(glob.glob(test_path + '/*'))[0]\n",
        "    original_vol = nib.load(original_vol_path)\n",
        "    original_shape = original_vol.shape\n",
        "\n",
        "    v = np.zeros(original_shape)\n",
        "    v = nib.Nifti1Image(v, original_vol.affine)  # to save this 3D (ndarry) numpy\n",
        "\n",
        "    if FLAIR_FLAG:\n",
        "        nib.save(v, test_path + '/' + f'BraTS2021_0{brats_num:04d}_flair.nii.gz')\n",
        "    if T1_FLAG:\n",
        "        nib.save(v, test_path + '/' + f'BraTS2021_0{brats_num:04d}_t1.nii.gz')\n",
        "    if T2_FLAG:\n",
        "        nib.save(v, test_path + '/' + f'BraTS2021_0{brats_num:04d}_t2.nii.gz')\n",
        "\n",
        "    if T1_FLAG and T2_FLAG:\n",
        "        nib.save(v, test_path + '/' + f'BraTS2021_0{brats_num:04d}_t1.nii.gz')\n",
        "        nib.save(v, test_path + '/' + f'BraTS2021_0{brats_num:04d}_t2.nii.gz')\n",
        "    if T1_FLAG and FLAIR_FLAG:\n",
        "        nib.save(v, test_path + '/' + f'BraTS2021_0{brats_num:04d}_t1.nii.gz')\n",
        "        nib.save(v, test_path + '/' + f'BraTS2021_0{brats_num:04d}_flair.nii.gz')\n",
        "    if T2_FLAG and FLAIR_FLAG:\n",
        "        nib.save(v, test_path + '/' + f'BraTS2021_0{brats_num:04d}_flair.nii.gz')\n",
        "        nib.save(v, test_path + '/' + f'BraTS2021_0{brats_num:04d}_t2.nii.gz')\n",
        "    print(\"Done\")\n",
        "\n",
        "def copy_subfolders_into_another_folder(paths_txt, source_folder, destination_folder):\n",
        "    # Read the contents of the file\n",
        "    with open(paths_txt, 'r') as file:\n",
        "        contents = file.read()\n",
        "\n",
        "    # Replace single quotes with double quotes\n",
        "    contents = contents.replace(\"'\", \"\\\"\")\n",
        "\n",
        "    # Load the JSON array, the list of subfolder names to copy\n",
        "    subfolder_names = json.loads(contents)\n",
        "\n",
        "    # Loop through each item in the source folder\n",
        "    for item in os.listdir(source_folder):\n",
        "        # If the item is a subfolder and its name is in the list\n",
        "        if os.path.isdir(os.path.join(source_folder, item)) and item in subfolder_names:\n",
        "            # Copy the subfolder to the destination folder\n",
        "            shutil.copytree(os.path.join(source_folder, item), os.path.join(destination_folder, item))\n",
        "\n",
        "    copy_subfolders_into_another_folder\n",
        "\n",
        "# The following function is responsible for returning the indices of the brain of the volume that contains foreground voxels.\n",
        "def find_brain_width_wise(dep, hei, i, img):        #cropping width wise\n",
        "    slice2D = img.get_fdata()[:, i, :]\n",
        "    for j in range(hei):\n",
        "        for k in range(dep):\n",
        "            if slice2D[j, k] != 0:\n",
        "                return i\n",
        "    return 0\n",
        "\n",
        "def find_brain_height_wise(dep, wid, i, img):      #cropping height wise\n",
        "    slice2D = img.get_fdata()[i, :, :]\n",
        "    for j in range(wid):\n",
        "        for k in range(dep):\n",
        "            if slice2D[j, k] != 0:\n",
        "                return i\n",
        "    return 0\n",
        "\n",
        "def find_brain_depth_wise(wid, hei, i, img):        #cropping depth wise\n",
        "    slice2D = img.get_fdata()[:, :, i]\n",
        "    for j in range(wid):\n",
        "        for k in range(hei):\n",
        "            if slice2D[j, k] != 0:\n",
        "                return i\n",
        "    return 0\n"
      ],
      "id": "zODj5gQguc5I"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f73677a6"
      },
      "source": [
        "### Reading Cropped BraTS21 examples, change the root_path to you base address"
      ],
      "id": "f73677a6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-Uk1K-6yf5W"
      },
      "outputs": [],
      "source": [
        "# !unzip '/content/drive/MyDrive/GP/T1c Validation.zip' -d '/content/Synthesized BraTS Validation Brain Cropped'\n",
        "!unzip '/content/drive/MyDrive/GP/Synthesized BraTS Validation Brain Cropped.zip'"
      ],
      "id": "9-Uk1K-6yf5W"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "551c0d68"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Just for Validation Set of BraTS\n",
        "'''\n",
        "\n",
        "\n",
        "root_path = '/content/drive/MyDrive/GP/BraTS Validation Brain Cropped'\n",
        "data_list = sorted(glob.glob(root_path + '/*'))                            #list of paths of the inside files\n",
        "# results_path = 'Synthesized BraTS Validation Brain Cropped/T1c Validation' #'Synthesized BraTS Validation Brain Cropped'\n",
        "results_path = 'Synthesized BraTS Validation Brain Cropped'"
      ],
      "id": "551c0d68"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsgnbDWCSB3e"
      },
      "source": [],
      "id": "hsgnbDWCSB3e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxPciiRfgNFM",
        "outputId": "4bda65f0-5157-4274-a4c5-d9e976e19058"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "251"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(sorted(glob.glob(results_path + '/*')))"
      ],
      "id": "gxPciiRfgNFM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ea173600"
      },
      "outputs": [],
      "source": [
        "# brats_num = input(\"please enter the brats number  \")\n",
        "# brats_num = '028'\n",
        "seq_1 = 'T2'\n",
        "seq_2 = 'FLAIR'"
      ],
      "id": "ea173600"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Po9A8FS7wbx1",
        "outputId": "9bbfca1c-168f-49bf-c076-b842d0f03b18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/MyDrive/GP/FINAL MODELS/T1---T1c/last.zip\n",
            "  inflating: /content/T1T1c Model/last/checkpoint  \n",
            "  inflating: /content/T1T1c Model/last/ckpt-54.data-00000-of-00001  \n",
            "  inflating: /content/T1T1c Model/last/ckpt-54.index  \n"
          ]
        }
      ],
      "source": [
        "!unzip '/content/drive/MyDrive/GP/FINAL MODELS/T1---T1c/last.zip' -d \"/content/T1T1c Model\""
      ],
      "id": "Po9A8FS7wbx1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6VLpsmeqCDaf"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "FOR GANs ONLY NOT CYCLE-GANS\n",
        "'''\n",
        "\n",
        "def downsample(filters, size, apply_norm=True):\n",
        "    initializer = tf.random_normal_initializer(0., 0.02)\n",
        "    result = tf.keras.Sequential()\n",
        "    result.add(tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n",
        "                                               kernel_initializer=initializer, use_bias=False))\n",
        "\n",
        "    if apply_norm:\n",
        "        result.add(tfal.InstanceNormalization(axis=-1))\n",
        "    result.add(tf.keras.layers.LeakyReLU())\n",
        "    return result\n",
        "\n",
        "def upsample(filters, size, apply_dropout=False):\n",
        "    initializer = tf.random_normal_initializer(0., 0.02)\n",
        "    result = tf.keras.Sequential()\n",
        "    result.add(tf.keras.layers.Conv2DTranspose(filters, size, strides=2, padding='same',\n",
        "                                               kernel_initializer=initializer, use_bias=False))\n",
        "    result.add(tfal.InstanceNormalization(axis=-1))\n",
        "    if apply_dropout:\n",
        "        result.add(tf.keras.layers.Dropout(0.5))\n",
        "    result.add(tf.keras.layers.ReLU())\n",
        "\n",
        "    return result\n",
        "\n",
        "def conv_block(x, num_filters):\n",
        "    x = L.Conv2D(num_filters, 3, padding=\"same\")(x)\n",
        "    x = tfal.InstanceNormalization(axis=-1)(x)\n",
        "    x = L.Activation(\"relu\")(x)\n",
        "\n",
        "    x = L.Conv2D(num_filters, 3, padding=\"same\")(x)\n",
        "    x = tfal.InstanceNormalization(axis=-1)(x)\n",
        "    x = L.Activation(\"relu\")(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def se_block(x, num_filters, ratio=8):\n",
        "    se_shape = (1, 1, num_filters)\n",
        "    se = L.GlobalAveragePooling2D()(x)\n",
        "    se = L.Reshape(se_shape)(se)\n",
        "    se = L.Dense(num_filters // ratio, activation=\"relu\", use_bias=False)(se)\n",
        "    se = L.Dense(num_filters, activation=\"sigmoid\", use_bias=False)(se)\n",
        "    se = L.Reshape(se_shape)(se)\n",
        "    x = L.Multiply()([x, se])\n",
        "    return x\n",
        "\n",
        "def encoder_block(x, num_filters):\n",
        "    x = conv_block(x, num_filters)\n",
        "    x = se_block(x, num_filters)\n",
        "    p = L.MaxPool2D((2, 2))(x)\n",
        "    return x, p\n",
        "\n",
        "def decoder_block(x, s, num_filters):\n",
        "    x = L.UpSampling2D(interpolation=\"bilinear\")(x)\n",
        "    x = L.Concatenate()([x, s])\n",
        "    x = conv_block(x, num_filters)\n",
        "    x = se_block(x, num_filters)\n",
        "    return x\n",
        "\n",
        "def squeeze_attention_unet(input_shape=(256, 256, 3)):\n",
        "    \"\"\" Inputs \"\"\"\n",
        "    inputs = L.Input(input_shape)\n",
        "\n",
        "    \"\"\" Encoder \"\"\"\n",
        "    s1, p1 = encoder_block(inputs, 64)\n",
        "    s2, p2 = encoder_block(p1, 128)\n",
        "    s3, p3 = encoder_block(p2, 256)\n",
        "    s4, p4 = encoder_block(p3, 512)\n",
        "\n",
        "\n",
        "    b1 = conv_block(p4, 1024)\n",
        "    b1 = se_block(b1, 1024)\n",
        "\n",
        "\n",
        "    \"\"\" Decoder \"\"\"\n",
        "    d =  decoder_block(b1, s4, 512)\n",
        "    d1 = decoder_block(d, s3, 256)\n",
        "    d2 = decoder_block(d1, s2, 128)\n",
        "    d3 = decoder_block(d2, s1, 64)\n",
        "\n",
        "    \"\"\" Outputs \"\"\"\n",
        "    outputs = L.Conv2D(3, (1, 1), activation='tanh')(d3)\n",
        "\n",
        "    \"\"\" Model \"\"\"\n",
        "\n",
        "    model = Model(inputs, outputs, name=\"Squeeze-Attention-UNET\")\n",
        "    return model\n",
        "\n",
        "def discriminator():\n",
        "    initializer = tf.random_normal_initializer(0., 0.02)\n",
        "    inp = tf.keras.layers.Input(shape=[256, 256, 3], name='input_image')\n",
        "    x = inp\n",
        "    down1 = downsample(64, 4, False)(x) # (bs, 16, 16, 64)\n",
        "    down2 = downsample(128, 4)(down1)\n",
        "    down3 = downsample(256, 4)(down2)\n",
        "\n",
        "\n",
        "    zero_pad1 = tf.keras.layers.ZeroPadding2D()(down3) # (bs, 34, 34, 256)\n",
        "    conv = tf.keras.layers.Conv2D(512, 4, strides=1, kernel_initializer=initializer,\n",
        "                                  use_bias=False)(zero_pad1) # (bs, 31, 31, 512)\n",
        "    norm1 = tfal.InstanceNormalization()(conv)\n",
        "    leaky_relu = tf.keras.layers.LeakyReLU()(norm1)\n",
        "    zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu) # (bs, 33, 33, 512)\n",
        "\n",
        "    last = tf.keras.layers.Conv2D(3, 4, strides=1, kernel_initializer=initializer)(zero_pad2) # (bs, 30, 30, 1)\n",
        "    return tf.keras.Model(inputs=inp, outputs=last)\n",
        "\n",
        "generator_g = squeeze_attention_unet() # Generates T2 images using T1 MRI Scans\n",
        "discriminator_x = discriminator()\n",
        "generator_g_optimizer = tf.keras.optimizers.legacy.Adam(2e-10, beta_1=0.5 )\n",
        "discriminator_x_optimizer = tf.keras.optimizers.legacy.Adam(2e-10, beta_1=0.5 )\n",
        "\n",
        "checkpoint_path = \"/content/T1T1c Model/last\"\n",
        "\n",
        "ckpt = tf.train.Checkpoint(generator_g=generator_g,\n",
        "                           discriminator_x=discriminator_x,\n",
        "                           generator_g_optimizer=generator_g_optimizer,\n",
        "                           discriminator_x_optimizer=discriminator_x_optimizer)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=300)\n",
        "\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "    print(f'Last Check Point: {ckpt_manager.latest_checkpoint}')\n",
        "    print('Latest checkpoint restored!!')"
      ],
      "id": "6VLpsmeqCDaf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hn8St9AEDLAO"
      },
      "outputs": [],
      "source": [
        "# !unzip '/content/drive/MyDrive/GP/Models/cp-25-Gans.zip'"
      ],
      "id": "Hn8St9AEDLAO"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71a61cac"
      },
      "source": [
        "# Predict"
      ],
      "id": "71a61cac"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b779ebb",
        "outputId": "e08e2cff-0731-4b0c-e711-54a5d97f3916"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer RandomNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# generator_g = ResNet().model\n",
        "# generator_f = ResNet().model\n",
        "\n",
        "# discriminator_x = Discriminator().model\n",
        "# discriminator_y = Discriminator().model\n",
        "\n",
        "# generator_g_optimizer = tf.keras.optimizers.legacy.Adam(8e-5)\n",
        "# generator_f_optimizer = tf.keras.optimizers.legacy.Adam(8e-5)\n",
        "# discriminator_x_optimizer = tf.keras.optimizers.legacy.Adam(8e-5)\n",
        "# discriminator_y_optimizer = tf.keras.optimizers.legacy.Adam(8e-5)"
      ],
      "id": "9b779ebb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4081162f",
        "outputId": "858cc114-295f-49ff-de6c-84147fca6d60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generator's parameters = 31,827,075\n",
            "Discriminator's parameters = 2,781,955\n"
          ]
        }
      ],
      "source": [
        "print(\"Generator's parameters = {:,}\".format(generator_g.count_params()))\n",
        "print(\"Discriminator's parameters = {:,}\".format(discriminator_x.count_params()))"
      ],
      "id": "4081162f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "13313186"
      },
      "outputs": [],
      "source": [
        "#TO DO: Generalize Path, add it to arguments\n",
        "def predict_image(img_input, model, img_true):\n",
        "    prediction = model(img_input)\n",
        "    pred_vol = prediction[0, :, :, 0].numpy().copy()\n",
        "    # error = tf.image.ssim(img_true, prediction, max_val=2)\n",
        "    return 0, pred_vol"
      ],
      "id": "13313186"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAvKoFAtFKjb",
        "outputId": "eb3051fe-bd50-481c-dde8-47e57d8ae784"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/MyDrive/GP/Models/FLAIR-T2-71.zip\n",
            "  inflating: FLAIR-T2-71/checkpoint  \n",
            "  inflating: FLAIR-T2-71/ckpt-71.data-00000-of-00001  \n",
            "  inflating: FLAIR-T2-71/ckpt-71.index  \n"
          ]
        }
      ],
      "source": [
        "# !unzip '/content/drive/MyDrive/GP/Models/T2-F 0-30.zip'\n",
        "!unzip '/content/drive/MyDrive/GP/Models/FLAIR-T2-71.zip'\n",
        "# !unzip '/content/drive/MyDrive/GP/Models/0-30-squeez.zip'"
      ],
      "id": "oAvKoFAtFKjb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d3a24b8",
        "outputId": "2babc3f7-a22c-45f0-b481-8b5448ecc660",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Last Check Point: /content/FLAIR-T2-71/ckpt-71 is restored\n"
          ]
        }
      ],
      "source": [
        "# checkpoint_path = r\"E:\\Graduation Project\\GIFs and Models\\Attention UNET-1\"\n",
        "# checkpoint_path = r\"E:\\Graduation Project\\GIFs and Models\\259 CheckPoint 17-2-2023-T1-FLAIR\"\n",
        "# checkpoint_path = r\"E:\\Graduation Project\\GIFs and Models\\ResNet-7 7-3-2023 T2-Flair-71\"\n",
        "checkpoint_path = '/content/FLAIR-T2-71'\n",
        "# checkpoint_path = '0-30-squeez'\n",
        "\n",
        "ckpt = tf.train.Checkpoint(generator_g=generator_g,\n",
        "                           generator_f=generator_f,\n",
        "                           discriminator_x=discriminator_x,\n",
        "                           discriminator_y=discriminator_y,\n",
        "                           generator_g_optimizer=generator_g_optimizer,\n",
        "                           generator_f_optimizer=generator_f_optimizer,\n",
        "                           discriminator_x_optimizer=discriminator_x_optimizer,\n",
        "                           discriminator_y_optimizer=discriminator_y_optimizer)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
        "\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "    # ckpt.restore(ckpt_manager.checkpoints[30-1])\n",
        "#     ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "    # print(f'Last Check Point: {ckpt_manager.checkpoints[30-1]} is restored')\n",
        "    print(f'Last Check Point: {ckpt_manager.latest_checkpoint} is restored')"
      ],
      "id": "4d3a24b8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a72fc8b9"
      },
      "outputs": [],
      "source": [
        "with open('BraTS Validation on SqzAtt T1-T2 30 epochs.log', 'w') as file:\n",
        "    file.write('')"
      ],
      "id": "a72fc8b9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bde453d"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "\n",
        "# Create a logger\n",
        "logger = logging.getLogger(__name__)\n",
        "logger.setLevel(logging.INFO)\n",
        "\n",
        "# Create a file handler and set the formatter\n",
        "file_handler = logging.FileHandler('/content/drive/MyDrive/GP/Models/BraTS Validation New on SqzAtt T1-T2 30 epochs.log')\n",
        "file_handler.setLevel(logging.INFO)\n",
        "formatter = logging.Formatter('Brats %(iteration)s - T1-FLAIR ssim = %(ssim_score).4f')\n",
        "file_handler.setFormatter(formatter)\n",
        "\n",
        "# Add the file handler to the logger\n",
        "logger.addHandler(file_handler)"
      ],
      "id": "0bde453d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0d9c5c23"
      },
      "source": [
        "# Copy from root to result"
      ],
      "id": "0d9c5c23"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7wtcIyQJjM7T"
      },
      "outputs": [],
      "source": [
        "import glob"
      ],
      "id": "7wtcIyQJjM7T"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "zZtzkow3GLEE",
        "outputId": "01ea92e7-84c8-4ac3-a3b6-db4b35ec3082"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/GP/BraTS Validation Brain Cropped'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "root_path"
      ],
      "id": "zZtzkow3GLEE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EgC2ufsqF7EU"
      },
      "outputs": [],
      "source": [
        "x = '/content/drive/MyDrive/GP/FINAL MODELS/Predicted Data/FINAL-GANS-T1c From T1 - 29 July 2023'\n",
        "\n",
        "# Get a list of all the subfolders in the source folder\n",
        "subfolders = [f.path for f in os.scandir(root_path) if f.is_dir()]\n",
        "\n",
        "# # Copy each subfolder to the two destination folders\n",
        "for folder in subfolders:\n",
        "    shutil.copytree(folder, os.path.join(x, os.path.basename(folder)))\n",
        "\n",
        "print(len(glob.glob(x + '/*')))\n",
        "\n",
        "total_files = 0\n",
        "for root, dirs, files in os.walk(x):\n",
        "    total_files += len(files)\n",
        "print('Total number of files in folder and subfolders:', total_files)"
      ],
      "id": "EgC2ufsqF7EU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfe6a149"
      },
      "outputs": [],
      "source": [
        "# root_path = '/content/drive/MyDrive/GP/BraTS Validation Brain Cropped'\n",
        "# results_path = r'E:\\Graduation Project\\Datasets\\Synthesized Brats 200-300 BC'\n",
        "results_data_list = sorted(glob.glob(results_path + '/*'))\n",
        "\n",
        "# T1_syn_result_vol_path = '/content/drive/MyDrive/GP/T2-FLAIR/ResNet-7(71 ep) - T1 Synth from FLAIR - BraTS Validation - Brain Cropped'\n",
        "# T2_syn_result_vol_path = '/content/drive/MyDrive/GP/FLAIR From T1 Using GANS (SSIM) - 31 May 2023'\n",
        "FLAIR_syn_result_vol_path = '/content/drive/MyDrive/GP/FINAL MODELS/Predicted Data/FINAL-GANS-T1c From T1 - 29 July 2023'\n",
        "\n",
        "# Get a list of all the subfolders in the source folder\n",
        "subfolders = [f.path for f in os.scandir(root_path) if f.is_dir()]\n",
        "\n",
        "# # Copy each subfolder to the two destination folders\n",
        "# for folder in subfolders:\n",
        "    # shutil.copytree(folder, os.path.join(T1_syn_result_vol_path, os.path.basename(folder)))\n",
        "    # shutil.copytree(folder, os.path.join(T2_syn_result_vol_path, os.path.basename(folder)))\n",
        "    # shutil.copytree(folder, os.path.join(FLAIR_syn_result_vol_path, os.path.basename(folder)))\n",
        "\n",
        "# T1_syn_result_vols = sorted(glob.glob(T1_syn_result_vol_path + '/*'))\n",
        "# T2_syn_result_vols = sorted(glob.glob(T2_syn_result_vol_path + '/*'))\n",
        "FLAIR_syn_result_vols = sorted(glob.glob(FLAIR_syn_result_vol_path + '/*'))"
      ],
      "id": "bfe6a149"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CRE-oszdaBLI"
      },
      "outputs": [],
      "source": [
        "results_data_list"
      ],
      "id": "CRE-oszdaBLI"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjC395PxmKsX",
        "outputId": "926feaeb-2242-4a0c-8825-125e75267890"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "251 251\n"
          ]
        }
      ],
      "source": [
        "T1_syn_result_vol_path = '/content/drive/MyDrive/GP/ResNet7(30 ep) - T1 Synth from FLAIR - BraTS Validation - Brain Cropped'\n",
        "# T2_syn_result_vol_path = '/content/drive/MyDrive/GP/T2 Synthesized BraTS Validation Brain Cropped/T2 Synthesized BraTS Validation Brain Cropped'\n",
        "FLAIR_syn_result_vol_path = '/content/drive/MyDrive/GP/ResNet7(30 ep) - FLAIR Synth from T1 - BraTS Validation - Brain Cropped'\n",
        "\n",
        "\n",
        "T1_syn_result_vols = sorted(glob.glob(T1_syn_result_vol_path + '/*'))\n",
        "FLAIR_syn_result_vols = sorted(glob.glob(FLAIR_syn_result_vol_path + '/*'))\n",
        "\n",
        "print(len(T1_syn_result_vols), len(FLAIR_syn_result_vols))"
      ],
      "id": "EjC395PxmKsX"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVJZBD5dsBtD",
        "outputId": "cd0473b9-265b-4e83-e0fe-16cbed71c5ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "251\n"
          ]
        }
      ],
      "source": [
        "for i in (sorted(glob.glob(FLAIR_syn_result_vol_path + '/*'))):\n",
        "  x = len( sorted(glob.glob(i + '/*')))\n",
        "  if x != 5:\n",
        "    print(i)\n",
        "\n",
        "print(len(FLAIR_syn_result_vols))"
      ],
      "id": "aVJZBD5dsBtD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "mQVoLuRWEzHo",
        "outputId": "2cc9728d-6934-4ee9-e7eb-346160a9c4c0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/GP/FINAL MODELS/Predicted Data/FINAL-GANS-FLAIR From T1c - 29 July 2023'"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "FLAIR_syn_result_vol_path"
      ],
      "id": "mQVoLuRWEzHo"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2b109c3"
      },
      "source": [
        "# Delete T1"
      ],
      "id": "d2b109c3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0eced285"
      },
      "outputs": [],
      "source": [
        "for dirpath, dirnames, filenames in os.walk(T1_syn_result_vol_path):\n",
        "    for filename in filenames:\n",
        "        if filename.endswith('t1.nii.gz'):\n",
        "            file_path = os.path.join(dirpath, filename)\n",
        "            os.remove(file_path)\n",
        "#             print(f\"{file_path} has been deleted.\")"
      ],
      "id": "0eced285"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37212bc0"
      },
      "source": [
        "# Delete T2"
      ],
      "id": "37212bc0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ef106373"
      },
      "outputs": [],
      "source": [
        "for dirpath, dirnames, filenames in os.walk(T2_syn_result_vol_path):\n",
        "    for filename in filenames:\n",
        "        if filename.endswith('t2.nii.gz'):\n",
        "            file_path = os.path.join(dirpath, filename)\n",
        "            os.remove(file_path)\n",
        "#             print(f\"{file_path} has been deleted.\")"
      ],
      "id": "ef106373"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92d88397"
      },
      "source": [
        "# Delete FLAIR"
      ],
      "id": "92d88397"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72567345"
      },
      "outputs": [],
      "source": [
        "for dirpath, dirnames, filenames in os.walk(FLAIR_syn_result_vol_path):\n",
        "    for filename in filenames:\n",
        "        if filename.endswith('flair.nii.gz'):\n",
        "            file_path = os.path.join(dirpath, filename)\n",
        "            os.remove(file_path)"
      ],
      "id": "72567345"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44IY9ji_FUDh"
      },
      "source": [
        "#Delete T1c"
      ],
      "id": "44IY9ji_FUDh"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8WgHNjUFTFR"
      },
      "outputs": [],
      "source": [
        "for dirpath, dirnames, filenames in os.walk(FLAIR_syn_result_vol_path):\n",
        "    for filename in filenames:\n",
        "        if filename.endswith('t1ce.nii.gz'):\n",
        "            file_path = os.path.join(dirpath, filename)\n",
        "            os.remove(file_path)"
      ],
      "id": "s8WgHNjUFTFR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5gjysc22CH9"
      },
      "outputs": [],
      "source": [
        "for i in (sorted(glob.glob(FLAIR_syn_result_vol_path + '/*'))):\n",
        "  x = len( sorted(glob.glob(i + '/*')))\n",
        "  if x != 4:\n",
        "    print(i)"
      ],
      "id": "V5gjysc22CH9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4thuI0Zl1wED",
        "outputId": "c9402e3e-f61f-4373-b35f-a64c7a8c734f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "251"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(sorted(glob.glob(FLAIR_syn_result_vol_path + '/*')))"
      ],
      "id": "4thuI0Zl1wED"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lX6u_cJq0_Ht",
        "outputId": "48dca3a6-0ff4-42d1-f95c-2d053fc5eaf7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of files in folder and subfolders: 1004\n"
          ]
        }
      ],
      "source": [
        "total_files = 0\n",
        "for root, dirs, files in os.walk(FLAIR_syn_result_vol_path):\n",
        "    total_files += len(files)\n",
        "\n",
        "print('Total number of files in folder and subfolders:', total_files)"
      ],
      "id": "lX6u_cJq0_Ht"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hM549FX_d8Ih"
      },
      "outputs": [],
      "source": [
        "SSIM1 = []\n",
        "SSIM2 = []\n",
        "\n",
        "vol_1 = []\n",
        "vol_2 = []\n",
        "\n",
        "ssim_1_list = []\n",
        "ssim_2_list = []\n",
        "\n",
        "order_1 = 0\n",
        "order_2 = 0\n",
        "\n",
        "ssim_score_1 = 0\n",
        "ssim_score_2 = 0\n",
        "\n",
        "seq_1 = 'T2'\n",
        "seq_2 = 'FLAIR'"
      ],
      "id": "hM549FX_d8Ih"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bw3iltmfv1Zr"
      },
      "outputs": [],
      "source": [
        "# results_data_list = results_data_list[246:]"
      ],
      "id": "Bw3iltmfv1Zr"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2TPIv77zaZB6"
      },
      "outputs": [],
      "source": [
        "results_data_list"
      ],
      "id": "2TPIv77zaZB6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "M6FavrFAHC6A",
        "outputId": "6337bcf9-d90f-4251-8e98-21fb608bf454"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'BraTS2021_00000_t1ce.nii.gz'"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.path.basename(sorted(glob.glob(data_list[0] + '/*'))[3])"
      ],
      "id": "M6FavrFAHC6A"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cmmO1vS6je48"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "for FLAIR GANS ONLYYY\n",
        "'''\n",
        "def predict_image_and_NO_loss(img_input, model):\n",
        "    prediction = model(img_input)\n",
        "    pred_vol = prediction[0, :, :, 0].numpy().copy()\n",
        "    return pred_vol\n",
        "\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "for i, path in enumerate(results_data_list):\n",
        "    T1_path = os.path.join(path, \"images\", \"GIF T1\")\n",
        "    dep = len(glob.glob(T1_path + '/**/*'))\n",
        "\n",
        "    GIF_T1 = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "                                  T1_path,\n",
        "                                  seed=123,\n",
        "                                  image_size=(256, 256),\n",
        "                                  batch_size=1,\n",
        "                                  shuffle = False)\n",
        "\n",
        "    GIF_T1 = GIF_T1.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "    GIF_T1 = GIF_T1.map(lambda x, _: (preprocess_image_train(x)))\n",
        "\n",
        "    for image_x in GIF_T1:\n",
        "        img_1 = predict_image_and_NO_loss(image_x, generator_g)\n",
        "        vol_2.append(img_1)\n",
        "\n",
        "    original_vol_path = sorted(glob.glob(data_list[i] + '/*'))[0]\n",
        "    original_vol = nib.load(original_vol_path)\n",
        "    original_shape = original_vol.shape\n",
        "\n",
        "    vol_2 = np.array(vol_2).transpose(1, 2, 0)\n",
        "\n",
        "    vol_2 = ndimage.zoom(vol_2, (original_shape[0]/vol_2.shape[0],\n",
        "                                 original_shape[1]/vol_2.shape[1],\n",
        "                                 original_shape[2]/vol_2.shape[2]), order=0)\n",
        "\n",
        "    v2 = nib.Nifti1Image(np.array(vol_2), original_vol.affine)\n",
        "    # FLAIR_name = os.path.basename(sorted(glob.glob(data_list[i] + '/*'))[0])  #for flair\n",
        "    FLAIR_name = os.path.basename(sorted(glob.glob(data_list[i] + '/*'))[3])   #for T1ce\n",
        "\n",
        "    FLAIR_res_path = os.path.join(FLAIR_syn_result_vols[i], FLAIR_name)\n",
        "    nib.save(v2, FLAIR_res_path)\n",
        "\n",
        "    vol_1 = []\n",
        "    vol_2 = []\n",
        "    print(f\"Volume #{i} is done\")"
      ],
      "id": "cmmO1vS6je48"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hcql5EeINdF_"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "source_folder_path = '/content/drive/MyDrive/GP/FINAL MODELS/Predicted Data/FINAL-GANS-T1c From T1 - 29 July 2023'\n",
        "destination_folder_path = '/content/drive/MyDrive/GP/FINAL MODELS/Predicted Data/Zipped'\n",
        "\n",
        "# Specify the name for the zip file\n",
        "zip_filename = os.path.basename(source_folder_path)\n",
        "\n",
        "# Create the full path for the zip file\n",
        "zip_filepath = os.path.join(destination_folder_path, zip_filename)\n",
        "\n",
        "# Create the zip file\n",
        "shutil.make_archive(zip_filepath, 'zip', source_folder_path)\n",
        "\n",
        "print(\"Zipping complete.\")"
      ],
      "id": "Hcql5EeINdF_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hltM-f90f-AI"
      },
      "outputs": [],
      "source": [
        "#DELETE THIS CELL THIS WAS BECAUSE YOU WERE TOO SLEEPY AND JUST WANTED TO MAKE MORE PREDICTIONS WHILE SLEEPING\n",
        "\n",
        "!unzip '/content/drive/MyDrive/GP/FINAL MODELS/T1c--FLAIR/LAST.zip' -d \"/content/T1c Model\"\n",
        "del generator_g\n",
        "del discriminator_x\n",
        "del generator_g_optimizer\n",
        "del discriminator_x_optimizer\n",
        "\n",
        "generator_g = squeeze_attention_unet()\n",
        "discriminator_x = discriminator()\n",
        "generator_g_optimizer = tf.keras.optimizers.legacy.Adam(2e-10, beta_1=0.5 )\n",
        "discriminator_x_optimizer = tf.keras.optimizers.legacy.Adam(2e-10, beta_1=0.5 )\n",
        "\n",
        "checkpoint_path = \"/content/T1c Model/LAST\"\n",
        "\n",
        "ckpt = tf.train.Checkpoint(generator_g=generator_g,\n",
        "                           discriminator_x=discriminator_x,\n",
        "                           generator_g_optimizer=generator_g_optimizer,\n",
        "                           discriminator_x_optimizer=discriminator_x_optimizer)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=300)\n",
        "\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "    print(f'Last Check Point: {ckpt_manager.latest_checkpoint}')\n",
        "    print('Latest checkpoint restored!!')\n",
        "\n",
        "print(\"Generator's parameters = {:,}\".format(generator_g.count_params()))\n",
        "print(\"Discriminator's parameters = {:,}\".format(discriminator_x.count_params()))\n",
        "\n",
        "xx = '/content/drive/MyDrive/GP/FINAL MODELS/Predicted Data/FINAL-GANS-FLAIR From T1c - 29 July 2023'\n",
        "subfolders = [f.path for f in os.scandir(root_path) if f.is_dir()]\n",
        "for folder in subfolders:\n",
        "    shutil.copytree(folder, os.path.join(xx, os.path.basename(folder)))\n",
        "print(len(glob.glob(xx + '/*')))\n",
        "\n",
        "total_files = 0\n",
        "for root, dirs, files in os.walk(xx):\n",
        "    total_files += len(files)\n",
        "print('Total number of files in folder and subfolders:', total_files)\n",
        "\n",
        "results_data_list = sorted(glob.glob(results_path + '/*'))\n",
        "FLAIR_syn_result_vol_path = '/content/drive/MyDrive/GP/FINAL MODELS/Predicted Data/FINAL-GANS-FLAIR From T1c - 29 July 2023'\n",
        "subfolders = [f.path for f in os.scandir(root_path) if f.is_dir()]\n",
        "FLAIR_syn_result_vols = sorted(glob.glob(FLAIR_syn_result_vol_path + '/*'))\n",
        "\n",
        "for i in (sorted(glob.glob(FLAIR_syn_result_vol_path + '/*'))):\n",
        "  x = len( sorted(glob.glob(i + '/*')))\n",
        "  if x != 5:\n",
        "    print(i)\n",
        "\n",
        "print(\"before  cropping: \")\n",
        "print(len(FLAIR_syn_result_vols))\n",
        "\n",
        "for dirpath, dirnames, filenames in os.walk(FLAIR_syn_result_vol_path):\n",
        "    for filename in filenames:\n",
        "        if filename.endswith('flair.nii.gz'):\n",
        "            file_path = os.path.join(dirpath, filename)\n",
        "            os.remove(file_path)\n",
        "\n",
        "for i in (sorted(glob.glob(FLAIR_syn_result_vol_path + '/*'))):\n",
        "  x = len( sorted(glob.glob(i + '/*')))\n",
        "  if x != 4:\n",
        "    print(i)\n",
        "\n",
        "print(\"after  cropping: \")\n",
        "print(len(FLAIR_syn_result_vols))\n",
        "\n",
        "total_files = 0\n",
        "for root, dirs, files in os.walk(FLAIR_syn_result_vol_path):\n",
        "    total_files += len(files)\n",
        "\n",
        "print('Total number of files in folder and subfolders:', total_files)\n",
        "\n",
        "SSIM1 = []\n",
        "SSIM2 = []\n",
        "\n",
        "vol_1 = []\n",
        "vol_2 = []\n",
        "\n",
        "ssim_1_list = []\n",
        "ssim_2_list = []\n",
        "\n",
        "order_1 = 0\n",
        "order_2 = 0\n",
        "\n",
        "ssim_score_1 = 0\n",
        "ssim_score_2 = 0\n",
        "\n",
        "seq_1 = 'T1c'\n",
        "seq_2 = 'FLAIR'\n",
        "\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "for i, path in enumerate(results_data_list):\n",
        "    T1_path = os.path.join(path, \"images\", \"GIF T1c\")\n",
        "    dep = len(glob.glob(T1_path + '/**/*'))\n",
        "\n",
        "    GIF_T1 = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "                                  T1_path,\n",
        "                                  seed=123,\n",
        "                                  image_size=(256, 256),\n",
        "                                  batch_size=1,\n",
        "                                  shuffle = False)\n",
        "\n",
        "    GIF_T1 = GIF_T1.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "    GIF_T1 = GIF_T1.map(lambda x, _: (preprocess_image_train(x)))\n",
        "\n",
        "    for image_x in GIF_T1:\n",
        "        img_1 = predict_image_and_NO_loss(image_x, generator_g)\n",
        "        vol_2.append(img_1)\n",
        "\n",
        "    original_vol_path = sorted(glob.glob(data_list[i] + '/*'))[0]\n",
        "    original_vol = nib.load(original_vol_path)\n",
        "    original_shape = original_vol.shape\n",
        "\n",
        "    vol_2 = np.array(vol_2).transpose(1, 2, 0)\n",
        "\n",
        "    vol_2 = ndimage.zoom(vol_2, (original_shape[0]/vol_2.shape[0],\n",
        "                                 original_shape[1]/vol_2.shape[1],\n",
        "                                 original_shape[2]/vol_2.shape[2]), order=0)\n",
        "\n",
        "    v2 = nib.Nifti1Image(np.array(vol_2), original_vol.affine)\n",
        "    FLAIR_name = os.path.basename(sorted(glob.glob(data_list[i] + '/*'))[0])\n",
        "    FLAIR_res_path = os.path.join(FLAIR_syn_result_vols[i], FLAIR_name)\n",
        "    nib.save(v2, FLAIR_res_path)\n",
        "\n",
        "    vol_1 = []\n",
        "    vol_2 = []\n",
        "    print(f\"Volume #{i} is done\")"
      ],
      "id": "hltM-f90f-AI"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mb7KZlS8Gf0u",
        "outputId": "4e02a2e0-b03c-455a-ccfc-b4b30f709be6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Zipping complete.\n",
            "Zipping complete.\n",
            "Zipping complete.\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "source_folder_path = '/content/drive/MyDrive/GP/FINAL MODELS/Predicted Data/FINAL-GANS-FLAIR From T2 - 29 July 2023'\n",
        "destination_folder_path = '/content/drive/MyDrive/GP/FINAL MODELS/Predicted Data/Zipped'\n",
        "zip_filename = 'FINAL-GANS-FLAIR From T2 - 29 July 2023'\n",
        "zip_filepath = os.path.join(destination_folder_path, zip_filename)\n",
        "shutil.make_archive(zip_filepath, 'zip', source_folder_path)\n",
        "print(\"Zipping complete.\")\n",
        "\n",
        "source_folder_path = '/content/drive/MyDrive/GP/FINAL MODELS/Predicted Data/FINAL-GANS-FLAIR From T1 - 29 July 2023'\n",
        "# destination_folder_path = '/content/drive/MyDrive/GP/Zip Synth Datasets/GANs-55-FLAIR from (T1, T2, T1c)'\n",
        "zip_filename = 'FINAL-GANS-FLAIR From T1 - 29 July 2023'\n",
        "zip_filepath = os.path.join(destination_folder_path, zip_filename)\n",
        "shutil.make_archive(zip_filepath, 'zip', source_folder_path)\n",
        "print(\"Zipping complete.\")\n",
        "\n",
        "source_folder_path = '/content/drive/MyDrive/GP/FINAL MODELS/Predicted Data/FINAL-GANS-FLAIR From T1c - 29 July 2023'\n",
        "# destination_folder_path = '/content/drive/MyDrive/GP/Zip Synth Datasets/GANs-55-FLAIR from (T1, T2, T1c)'\n",
        "zip_filename = 'FINAL-GANS-FLAIR From T1c - 29 July 2023'\n",
        "zip_filepath = os.path.join(destination_folder_path, zip_filename)\n",
        "shutil.make_archive(zip_filepath, 'zip', source_folder_path)\n",
        "print(\"Zipping complete.\")"
      ],
      "id": "Mb7KZlS8Gf0u"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "tIRfMsOsP7oI",
        "outputId": "0d6ff05d-7a28-4137-f7d8-bf9e72e0922b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Synthesized BraTS Validation Brain Cropped/BraTS2021_00000'"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results_data_list[0]"
      ],
      "id": "tIRfMsOsP7oI"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7d72a500"
      },
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "for i, path in enumerate(results_data_list):\n",
        "    T1_path = os.path.join(path, \"images\", \"GIF T1\")\n",
        "    # T2_path = os.path.join(path, \"images\", \"GIF T2\")\n",
        "    FLAIR_path = os.path.join(path, \"images\", \"GIF Flair\") ###### check this T1c instead of FLAIR\n",
        "    # T1c_path = os.path.join(path, \"images\", \"GIF T1c\")\n",
        "\n",
        "    dep = len(glob.glob(FLAIR_path + '/**/*'))\n",
        "\n",
        "    GIF_T1 = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "                                  T1_path,\n",
        "                                  seed=123,\n",
        "                                  image_size=(256, 256),\n",
        "                                  batch_size=1,\n",
        "                                  shuffle = False)\n",
        "\n",
        "    # GIF_T2 = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    #                               T2_path,\n",
        "    #                               seed=123,\n",
        "    #                               image_size=(256, 256),\n",
        "    #                               batch_size=1,\n",
        "    #                               shuffle = False)\n",
        "\n",
        "    GIF_FLAIR = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "                                  FLAIR_path,\n",
        "                                  seed=123,\n",
        "                                  image_size=(256, 256),\n",
        "                                  batch_size=1,\n",
        "                                  shuffle = False)\n",
        "\n",
        "    # GIF_T1c = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    #                               T1c_path,\n",
        "    #                               seed=123,\n",
        "    #                               image_size=(256, 256),\n",
        "    #                               batch_size=1,\n",
        "    #                               shuffle = False)\n",
        "\n",
        "    GIF_T1 = GIF_T1.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "    # GIF_T2 = GIF_T2.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "    GIF_FLAIR = GIF_FLAIR.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "    GIF_T1c = GIF_T1c.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "    # GIF_T1 = GIF_T1.map(lambda x, _: (preprocess_image_train(x)))\n",
        "    # GIF_T2 = GIF_T2.map(lambda x, _: (preprocess_image_train(x)))\n",
        "    GIF_FLAIR = GIF_FLAIR.map(lambda x, _: (preprocess_image_train(x)))\n",
        "    GIF_T1c = GIF_T1c.map(lambda x, _: (preprocess_image_train(x)))\n",
        "\n",
        "\n",
        "    for image_x, image_y in tf.data.Dataset.zip((GIF_T1c, GIF_FLAIR)):\n",
        "        ssim_1, img_1 = predict_image_and_calc_loss(image_x, generator_g, image_y) #predict_image_and_calc_loss\n",
        "        ssim_score_1 = ssim_score_1 + ssim_1\n",
        "        ssim_2_list.append(ssim_1)\n",
        "        vol_2.append(img_1)\n",
        "\n",
        "    # for image_x, image_y in tf.data.Dataset.zip((GIF_T1, GIF_FLAIR)):\n",
        "    #     ssim_2, img_2 = predict_image_and_calc_loss(image_y, generator_f, image_x)\n",
        "    #     ssim_score_2 = ssim_score_2 + ssim_2\n",
        "    #     ssim_1_list.append(ssim_2)\n",
        "    #     vol_1.append(img_2)\n",
        "\n",
        "    ssim_score_1, ssim_score_2 = ssim_score_1/dep , ssim_score_2/dep\n",
        "    # ssim_score_1 = ssim_score_1/dep\n",
        "    # logger.info('', extra={'iteration': i+1, 'ssim_score': ssim_score_1.numpy()[0]})\n",
        "    # logger.info('', extra={'iteration': i+1, 'ssim_score': ssim_score_2.numpy()[0]})\n",
        "\n",
        "\n",
        "    original_vol_path = sorted(glob.glob(data_list[i] + '/*'))[0]\n",
        "    original_vol = nib.load(original_vol_path)\n",
        "    original_shape = original_vol.shape\n",
        "\n",
        "\n",
        "    # vol_1 = np.array(vol_1).transpose(1, 2, 0)\n",
        "    vol_2 = np.array(vol_2).transpose(1, 2, 0)\n",
        "\n",
        "    # vol_1 = ndimage.zoom(vol_1, (original_shape[0]/vol_1.shape[0],\n",
        "    #                              original_shape[1]/vol_1.shape[1],\n",
        "    #                              original_shape[2]/vol_1.shape[2]), order=0)\n",
        "\n",
        "    vol_2 = ndimage.zoom(vol_2, (original_shape[0]/vol_2.shape[0],\n",
        "                                 original_shape[1]/vol_2.shape[1],\n",
        "                                 original_shape[2]/vol_2.shape[2]), order=0)\n",
        "\n",
        "\n",
        "    # v1 = nib.Nifti1Image(np.array(vol_1), original_vol.affine)            # to save this 3D (ndarry) numpy\n",
        "    v2 = nib.Nifti1Image(np.array(vol_2), original_vol.affine)            # to save this 3D (ndarry) numpy\n",
        "\n",
        "    # T1_name = os.path.basename(sorted(glob.glob(data_list[i] + '/*'))[2])\n",
        "    # T2_name = os.path.basename(sorted(glob.glob(data_list[i] + '/*'))[4])\n",
        "    FLAIR_name = os.path.basename(sorted(glob.glob(data_list[i] + '/*'))[0])\n",
        "\n",
        "    # T1_res_path = os.path.join(T1_syn_result_vols[i], T1_name)\n",
        "    # T2_res_path = os.path.join(T2_syn_result_vols[i], T2_name)\n",
        "    FLAIR_res_path = os.path.join(FLAIR_syn_result_vols[i], FLAIR_name)\n",
        "\n",
        "\n",
        "    # Save the Nifti image to a file\n",
        "    # nib.save(v1, T1_res_path)\n",
        "    # nib.save(v2, T2_res_path)\n",
        "    nib.save(v2, FLAIR_res_path)\n",
        "\n",
        "\n",
        "    vol_1 = []\n",
        "    vol_2 = []\n",
        "\n",
        "    SSIM1.append(ssim_score_1)\n",
        "    SSIM2.append(ssim_score_2)\n",
        "\n",
        "    ssim_score_1 = 0\n",
        "    ssim_score_2 = 0\n",
        "    print(f\"Volume #{i} is done\")"
      ],
      "id": "7d72a500"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wzMbj1RuPtY",
        "outputId": "9a8e201b-b947-4950-8224-42611f9bfb34"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0.0, 0.0, 0.0, 0.0, 0.0]"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "SSIM1"
      ],
      "id": "7wzMbj1RuPtY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cH7MkpciV09",
        "outputId": "6908bcda-9939-4173-9c4e-934ae4177589"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "251"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "for i in (sorted(glob.glob(FLAIR_syn_result_vol_path + '/*'))):\n",
        "  x = len( sorted(glob.glob(i + '/*')))\n",
        "  if x != 5:\n",
        "    print(i)\n",
        "\n",
        "len(sorted(glob.glob(FLAIR_syn_result_vol_path + '/*')))"
      ],
      "id": "2cH7MkpciV09"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9abef04",
        "outputId": "6b9cb7f4-9910-4c83-c5f6-2d8d9750201f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Volume #0 is done\n"
          ]
        }
      ],
      "source": [
        "T2_res_path = os.path.join(T2_syn_result_vols[i], T2_name)\n",
        "FLAIR_res_path = os.path.join(FLAIR_syn_result_vols[i], FLAIR_name)\n",
        "\n",
        "\n",
        "# Save the Nifti image to a file\n",
        "nib.save(v1, FLAIR_res_path)\n",
        "#     nib.save(v2, T2_res_path)\n",
        "nib.save(v2, T2_res_path)\n",
        "\n",
        "\n",
        "vol_1 = []\n",
        "vol_2 = []\n",
        "\n",
        "ssim_score_1 = 0\n",
        "ssim_score_2 = 0\n",
        "print(f\"Volume #{i} is done\")"
      ],
      "id": "d9abef04"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "111a4a4a",
        "outputId": "907e69c5-7e02-4752-a84f-8bc68e5daedb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(135, 256, 256)"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.shape(vol_1)"
      ],
      "id": "111a4a4a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1cc58f1",
        "outputId": "82c33eae-fbfc-4c8f-f151-fccfe79ffcb0",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ssim_score for first Conversion = 0.6095 \n",
            "ssim_score for second Conversion = 0.6937 \n"
          ]
        }
      ],
      "source": [
        "ssim_score_1, ssim_score_2 = ssim_score_1/dep , ssim_score_2/dep\n",
        "\n",
        "\n",
        "print(\"ssim_score for first Conversion = {:.4f} \".format(ssim_score_1.numpy()[0]))\n",
        "print(\"ssim_score for second Conversion = {:.4f} \".format(ssim_score_2.numpy()[0]))"
      ],
      "id": "c1cc58f1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1136fb51",
        "outputId": "18ed2050-0b26-4591-8c08-c703c2e90d65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.0 3724.0\n",
            "-1.0 0.9064252972602844\n"
          ]
        }
      ],
      "source": [
        "original_vol_path = sorted(glob.glob(root_path + '/*'))[0]\n",
        "original_vol = nib.load(original_vol_path)\n",
        "x = original_vol.get_fdata()\n",
        "print(x.min(), x.max())\n",
        "\n",
        "\n",
        "\n",
        "original_vol = nib.load(r'E:\\Graduation Project\\GIFs and Models\\Brats 006\\Testing Synthesis With Segmentation on BraTS #006\\FLAIR.nii.gz')\n",
        "x = original_vol.get_fdata()\n",
        "print(x.min(), x.max())"
      ],
      "id": "1136fb51"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8afb1c18"
      },
      "outputs": [],
      "source": [
        "original_vol_path = sorted(glob.glob(root_path + '/*'))[0]\n",
        "original_vol = nib.load(original_vol_path)\n",
        "original_shape = original_vol.shape\n",
        "\n",
        "result_vol_path = r'E:\\Graduation Project\\GIFs and Models\\Brats {}\\Synthesized Volumes'.format(brats_num)\n",
        "if not os.path.exists(result_vol_path):\n",
        "    os.makedirs(result_vol_path)\n",
        "\n",
        "vol_1 = np.array(vol_1).transpose(1, 2, 0)\n",
        "vol_2 = np.array(vol_2).transpose(1, 2, 0)\n",
        "\n",
        "\n",
        "vol_1 = ndimage.zoom(vol_1, (original_shape[0]/vol_1.shape[0],\n",
        "                                             original_shape[1]/vol_1.shape[1],\n",
        "                                             original_shape[2]/vol_1.shape[2]), order=0)\n",
        "\n",
        "vol_2 = ndimage.zoom(vol_2, (original_shape[0]/vol_2.shape[0],\n",
        "                                             original_shape[1]/vol_2.shape[1],\n",
        "                                             original_shape[2]/vol_2.shape[2]), order=0)\n",
        "\n",
        "\n",
        "v1 = nib.Nifti1Image(np.array(vol_1), original_vol.affine)            # to save this 3D (ndarry) numpy\n",
        "v2 = nib.Nifti1Image(np.array(vol_2), original_vol.affine)            # to save this 3D (ndarry) numpy\n",
        "\n",
        "\n",
        "# Save the Nifti image to a file\n",
        "nib.save(v1, result_vol_path + '/' + 'T1.nii.gz')\n",
        "nib.save(v2, result_vol_path + '/' + 'T2.nii.gz')"
      ],
      "id": "8afb1c18"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e475220c"
      },
      "outputs": [],
      "source": [
        "anim_file = r'E:\\Graduation Project\\GIFs and Models\\Brats {}\\Predicted\\{}-{}.gif'.format(brats_num, seq_1, seq_2)\n",
        "\n",
        "with imageio.get_writer(anim_file, mode='I') as writer:\n",
        "  filenames = glob.glob(r'E:\\Graduation Project\\GIFs and Models\\Brats {}\\Predicted\\{}-{}-GIF\\*.png'.format(brats_num, seq_1, seq_2))\n",
        "  filenames = sorted(filenames)\n",
        "  filenames = list(Tcl().call('lsort', '-dict', filenames))\n",
        "  for filename in filenames:\n",
        "    image = imageio.imread(filename)\n",
        "    writer.append_data(image)\n",
        "  image = imageio.imread(filename)\n",
        "  writer.append_data(image)\n",
        "\n",
        "embed.embed_file(anim_file)"
      ],
      "id": "e475220c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a375c98b"
      },
      "outputs": [],
      "source": [
        "anim_file = r'E:\\Graduation Project\\GIFs and Models\\Brats {}\\Predicted\\{}-{}.gif'.format(brats_num, seq_2, seq_1)\n",
        "\n",
        "with imageio.get_writer(anim_file, mode='I') as writer:\n",
        "  filenames = glob.glob(r'E:\\Graduation Project\\GIFs and Models\\Brats {}\\Predicted\\{}-{}-GIF\\*.png'.format(brats_num, seq_2, seq_1))\n",
        "  filenames = sorted(filenames)\n",
        "  filenames = list(Tcl().call('lsort', '-dict', filenames))\n",
        "  for filename in filenames:\n",
        "    image = imageio.imread(filename)\n",
        "    writer.append_data(image)\n",
        "  image = imageio.imread(filename)\n",
        "  writer.append_data(image)\n",
        "\n",
        "embed.embed_file(anim_file)"
      ],
      "id": "a375c98b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "964a8ece"
      },
      "outputs": [],
      "source": [],
      "id": "964a8ece"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}