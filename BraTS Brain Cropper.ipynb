{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<p align=\"center\">\n",
    "<font color=\"#34ebeb\" font size = 10>Background Cropper of Brain Volume :brain: </font>\n",
    "</p>\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Reading all BraTS21 examples, change the root_path to you base address"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "root_path = r'Old_Tests/Test_dataset_crop'             #Change this to dataset base address\n",
    "data_list = sorted(glob.glob(root_path + '/*'))        #list of paths of the inside files"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### The following function is responsible for returning the indices of the brain of the volume that contains foreground voxels."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "def find_brain_width_wise(dep, hei):        #cropping width wise\n",
    "    slice2D = img.get_fdata()[:, i, :]\n",
    "    for j in range(hei):\n",
    "        for k in range(dep):\n",
    "            if slice2D[j, k] != 0:\n",
    "                return i\n",
    "    return 0\n",
    "\n",
    "def find_brain_height_wise(dep, wid):      #cropping height wise\n",
    "    slice2D = img.get_fdata()[i, :, :]\n",
    "    for j in range(wid):\n",
    "        for k in range(dep):\n",
    "            if slice2D[j, k] != 0:\n",
    "                return i\n",
    "    return 0\n",
    "\n",
    "def find_brain_depth_wise(wid, hei):        #cropping depth wise\n",
    "    slice2D = img.get_fdata()[:, :, i]\n",
    "    for j in range(wid):\n",
    "        for k in range(hei):\n",
    "            if slice2D[j, k] != 0:\n",
    "                return i\n",
    "    return 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Creating results folder that will contain the cropped volumes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# Create results folder\n",
    "results_path_path = r'Brats21_BrainVol_Cropped'\n",
    "if not os.path.exists(results_path_path):\n",
    "    os.makedirs(results_path_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Looping in every example and in every module in the volume to crop it to contain only the brain part"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Iterating for every example in the folder\n",
    "for vol in data_list:\n",
    "    modules_list = sorted(glob.glob(vol + '/*'))          #modules list of a single volume\n",
    "    seg_vol_path = modules_list[0]                        #It doesn't matter which mode, just no seg (tumor), as we want the brain\n",
    "    img = nib.load(seg_vol_path)                          #Flair volume (it doesn't matter)\n",
    "\n",
    "    height, width, depth = img.shape\n",
    "    filled_slices_width = []                              #slices indices with foreground values\n",
    "    filled_slices_height = []\n",
    "    filled_slices_depth = []\n",
    "\n",
    "    #Iterating in the dimension of interest, which we will extract foreground slices from, repeating it in the 3 dimension (3D Volume)\n",
    "    for i in range(depth):\n",
    "        depth_idx = find_brain_depth_wise(width, height)\n",
    "        if depth_idx != 0:\n",
    "            filled_slices_depth.append(depth_idx)\n",
    "\n",
    "    for i in range(width):\n",
    "        width_idx = find_brain_width_wise(depth, height)\n",
    "        if width_idx != 0:\n",
    "            filled_slices_width.append(width_idx)\n",
    "\n",
    "    for i in range(height):\n",
    "        height_idx = find_brain_height_wise(depth, width)\n",
    "        if height_idx != 0:\n",
    "            filled_slices_height.append(height_idx)\n",
    "\n",
    "\n",
    "    min_wid_idx, max_wid_idx = filled_slices_width[0], filled_slices_width[-1]\n",
    "    min_hei_idx, max_hei_idx = filled_slices_height[0], filled_slices_height[-1]\n",
    "    min_dep_idx, max_dep_idx = filled_slices_depth[0], filled_slices_depth[-1]\n",
    "\n",
    "    #Cropping step, iterating for every module in the same example to be cropped.\n",
    "    for module_path in modules_list:\n",
    "        module_vol = nib.load(module_path)\n",
    "        cropped_vol = module_vol.get_fdata()[min_hei_idx : (max_hei_idx+1),\n",
    "                                             min_wid_idx : (max_wid_idx+1),\n",
    "                                             min_dep_idx : (max_dep_idx+1)]\n",
    "\n",
    "        nifti_img =  nib.Nifti1Image(cropped_vol, module_vol.affine)            # to save this 3D (ndarry) numpy\n",
    "\n",
    "        #to make the naming of the resulted folders and files the same as the original naming\n",
    "        vol_new_path = results_path_path + '/' +vol.split('\\\\')[1]\n",
    "        if not os.path.exists(vol_new_path):\n",
    "            os.makedirs(vol_new_path)\n",
    "\n",
    "        module_new_path = vol_new_path + '/' + module_path.split('\\\\')[-1]\n",
    "        nib.save(nifti_img, module_new_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Testing random module"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "(134, 177, 135)"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_path = r'Brats21_BrainVol_Cropped/BraTS2021_00006/BraTS2021_00006_t2.nii.gz'\n",
    "img_test = img = nib.load(test_path)\n",
    "\n",
    "img_test.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Image shape was (240, 240, 155) Before cropping, now it's (134, 177, 135) for this example (Random)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}